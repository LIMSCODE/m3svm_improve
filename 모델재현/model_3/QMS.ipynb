import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Define QMSModel
class QMSModel(nn.Module):
    def __init__(self, input_dim, num_classes):
        super(QMSModel, self).__init__()
        self.fc_weights = nn.Parameter(torch.randn(num_classes, input_dim, input_dim))
        self.fc_bias = nn.Parameter(torch.randn(num_classes, input_dim))

    def forward(self, x):
        x_flat = x.view(x.size(0), -1)  # Flatten input
        # Compute quadratic scores for all classes simultaneously
        # 이 함수는 입력 데이터를 펼친 뒤, 각 클래스별로 이차 함수와 선형 함수를 계산하여 점수를 반환
        quadratic_scores = torch.einsum('bi,nij,bj->bn', x_flat, self.fc_weights, x_flat)
        linear_scores = torch.einsum('bi,ni->bn', x_flat, self.fc_bias)
        return quadratic_scores + linear_scores

# Data preparation
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_loader = DataLoader(
    datasets.FashionMNIST(root='./fashionMnist', train=True, download=True, transform=transform),
    batch_size=128, shuffle=True  # Increased batch size for better GPU utilization
)
test_loader = DataLoader(
    datasets.FashionMNIST(root='./fashionMnist', train=False, download=True, transform=transform),
    batch_size=128, shuffle=False
)

# Instantiate the model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = QMSModel(input_dim=28 * 28, num_classes=10).to(device)

# Optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
for epoch in range(5):  # Reduced epochs for faster training
    model.train()
    correct, total = 0, 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()

        outputs = model(inputs)
        loss = nn.CrossEntropyLoss()(outputs, labels)

        loss.backward()
        optimizer.step()

        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    print(f'Epoch {epoch + 1}, Accuracy: {100 * correct / total:.2f}%')

# Testing loop
model.eval()
correct, total = 0, 0
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Test Accuracy: {100 * correct / total:.2f}%')

# Visualize predictions
def plot_images(images, labels, preds, num_images=6):
    fig, axes = plt.subplots(1, num_images, figsize=(12, 3))
    for i in range(num_images):
        ax = axes[i]
        ax.imshow(images[i].squeeze().cpu(), cmap='gray')
        ax.set_title(f"True: {labels[i]}, Pred: {preds[i]}")
        ax.axis('off')
    plt.show()

data_iter = iter(test_loader)
images, labels = next(data_iter)
images, labels = images.to(device), labels.to(device)
outputs = model(images)
_, preds = torch.max(outputs, 1)

plot_images(images.cpu(), labels.cpu(), preds.cpu())
