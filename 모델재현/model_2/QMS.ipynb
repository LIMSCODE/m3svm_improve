# %%
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Define the QMS Model
class QMSModel(nn.Module):
    def __init__(self, input_dim, num_classes):
        super(QMSModel, self).__init__()
        self.input_dim = input_dim
        self.num_classes = num_classes
        # Linear layer to map the 28x28 image into the desired output dimension
        self.fc = nn.Linear(input_dim, num_classes)
    def forward(self, x):
        # Flatten the image (28x28 -> 784)
        x = x.view(x.size(0), -1)  
        # Flatten the input tensor
        # The issue was with the quadratic term calculation and reshaping
        # Removed quadratic transformation, keeping original input
        # output = self.fc(quadratic_term.view(x.size(0), -1))  # Apply linear layer
        output = self.fc(x) # Directly pass the flattened input to the fully connected layer
        return output                   #출력값은 각 클래스에 대한 점수
# Define the transformation to normalize the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
]) 

 
# Load the Fashion MNIST dataset
train_dataset = datasets.FashionMNIST(root='./fashionMnist', train=True, download=True, transform=transform)
test_dataset = datasets.FashionMNIST(root='./fashionMnist', train=False, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
# Instantiate the model
model = QMSModel(input_dim=28*28, num_classes=10)
# 28x28 images, 10 classes
# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)


 
# 모델을 훈련한다 
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        optimizer.zero_grad()
 
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels) 
        # Backward pass
        loss.backward()
        optimizer.step()  

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)    # output :각 샘플에 대해 모델이 예측한 클래스(0~9).
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = 100 * correct / total
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')
  




# 모델을 테스트한다
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()           #모델예측이 맞으면 정확도+1

test_accuracy = 100 * correct / total
print(f'Test Accuracy: {test_accuracy:.2f}%')


# 훈련시킨 모델로 예측후 outputs를 만들어내고 torch.max로 예측후 시각화
def plot_images(images, labels, preds, num_images=6):
    fig, axes = plt.subplots(1, num_images, figsize=(12, 3))
    for i in range(num_images):
        ax = axes[i]
        ax.imshow(images[i].squeeze(), cmap='gray')
        ax.set_title(f"True: {labels[i]}, Pred: {preds[i]}")
        ax.axis('off')
    plt.show()

 
# Get some test images and predictions
data_iter = iter(test_loader)
images, labels = next(data_iter)
outputs = model(images)
_, preds = torch.max(outputs, 1) # 분류문제에서 outputs는 [batch_size, num_classes] , 
# outputs[i]가 [2.5, 1.1, 3.7, -0.5]일 경우, torch.max(outputs[i], 0)는 (3.7, 2)를 반환 
# _는 무효, pred는 인덱스값의미
# 만약 모델이 preds = [2, 4, 1, 0, ...]라고 예측했다면, 
# 이것은 모델이 첫 번째 이미지에 대해 클래스 2 (예: 티셔츠)을 예측했다는 뜻 
# plot_images 함수는 일부 테스트 이미지를 선택하고, 해당 이미지에 대해 True 라벨과 Predicted 라벨을 함께 표시하여 예측
 
# True Label
# 0: 티셔츠/탑 (T-shirt/top) / 1: 바지 (Trouser) / 2: 풀오버 (Pullover)
# 3: 드레스 (Dress) / 4: 코트 (Coat) / 5: 샌들 (Sandal)
# 6: 셔츠 (Shirt) / 7: 스니커즈 (Sneaker) / 8: 가방 (Bag) / 9: 앵클 부츠 (Ankle boot)
plot_images(images, labels, preds)
 
# %%
